{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Index","text":"<ol> <li> <p>Overview Provides a general introduction to the GPU Monitoring and Carbon Calculation Tool, explaining its purpose and key features.</p> </li> <li> <p>Installation Step-by-step instructions for setting up the tool, including setting up the virtual environment and installing dependencies.</p> </li> <li> <p>Benchmark Docker Images Instructions for managing and building Docker images for benchmarking, including how to add custom benchmarks, understand the directory structure, and pull images from the GitHub Container Registry.</p> </li> <li> <p>Command-Line Interface Explains the available command-line arguments and options for controlling the tool\u2019s behavior and features.</p> </li> <li> <p>Example Commands Provides practical examples of how to run the tool with different configurations using common command-line commands.</p> </li> <li> <p>Collecting Results Details how the tool collects, formats, and stores results, including GPU performance and carbon emission data.</p> </li> <li> <p>Live Monitoring Describes how to enable and use the live monitoring feature to track GPU metrics and benchmark performance in real-time.</p> </li> <li> <p>Considerations On Accuracy Discusses limitations and accuracy considerations regarding the measurement of GPU metrics and carbon emissions.</p> </li> <li> <p>Future Work and Expansion Outlines the future improvements and tasks that are planned or currently being worked on for the tool.</p> </li> </ol>"},{"location":"building_docker_images/","title":"Benchmark Docker Images","text":"<p>Here\u2019s the updated documentation with a new section added for building images locally and updated references for Harbor:</p>"},{"location":"building_docker_images/#available-benchmark-images","title":"Available Benchmark Images","text":"<p>The repository includes various Docker images for benchmarking. Below is a list of available images and their purposes:</p>"},{"location":"building_docker_images/#mantid-imaging-benchmarks","title":"Mantid Imaging Benchmarks","text":"<ul> <li><code>mantid_run_1</code>: Dockerfile for a Mantid benchmark with 1GB of data.</li> <li><code>mantid_run_4</code>: Dockerfile for a Mantid benchmark with 4GB of data.</li> <li><code>mantid_run_5</code>: Dockerfile for a Mantid benchmark with 5GB of data.</li> <li><code>mantid_run_8</code>: Dockerfile for a Mantid benchmark with 8GB of data.</li> </ul> <p>For more details, visit the Mantid Imaging Benchmarks Repository.</p>"},{"location":"building_docker_images/#sciml-benchmarks","title":"SciML Benchmarks","text":"<ul> <li><code>mnist_tf_keras</code>: Dockerfile for MNIST classification using TensorFlow/Keras. (NOT WORKING)</li> <li><code>stemdl_classification</code>: Dockerfile for STEMDL classification, this benchmark will utilize multiple gpus, if available. Uses parameters <code>-b epochs 3</code>.</li> <li><code>synthetic_regression</code>: Dockerfile for synthetic regression benchmarks with parameters <code>-b hidden_size 9000 -b epochs 3</code>.</li> </ul> <p>For more information, check the SCIML Bench Repository. These Dockerfiles clone a forked version of the SCIML-Bench repo.</p>"},{"location":"building_docker_images/#dummy-benchmark-container","title":"Dummy Benchmark Container","text":"<ul> <li><code>dummy</code>: A Dockerfile for a container used to profile GPU resource usage. This container runs for 5 minutes and helps assess the impact of the monitoring tool. For more details on profiling tests, see Profiling the Monitor's Impact on GPU Resources.</li> </ul>"},{"location":"building_docker_images/#base-images","title":"Base Images","text":"<ul> <li><code>sciml_base</code>: Base image for SciML (Scientific Machine Learning) benchmarks.</li> <li><code>mantid_base</code>: Base image tailored for Mantid imaging benchmarks.</li> </ul>"},{"location":"building_docker_images/#directory-structure","title":"Directory Structure","text":"<p>The repository's Dockerfiles are organized as follows:</p> <pre><code>dockerfiles/\n\u251c\u2500\u2500 app_images\n\u2502   \u251c\u2500\u2500 Dockerfile.dummy\n\u2502   \u251c\u2500\u2500 mantid_bench\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile.mantid_run_1\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile.mantid_run_4\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile.mantid_run_5\n\u2502   \u2502   \u2514\u2500\u2500 Dockerfile.mantid_run_8\n\u2502   \u2514\u2500\u2500 sciml_bench\n\u2502       \u251c\u2500\u2500 Dockerfile.mnist_tf_keras\n\u2502       \u251c\u2500\u2500 Dockerfile.stemdl_classification\n\u2502       \u2514\u2500\u2500 Dockerfile.synthetic_regression\n\u251c\u2500\u2500 base_images\n\u2502   \u251c\u2500\u2500 Dockerfile.mantid_base\n\u2502   \u2514\u2500\u2500 Dockerfile.sciml_base\n\u251c\u2500\u2500 build_images.sh\n\u2514\u2500\u2500 pull_images.sh\n</code></pre>"},{"location":"building_docker_images/#explanation","title":"Explanation:","text":"<ul> <li><code>app_images</code>: Contains Dockerfiles for specific benchmark applications.</li> <li><code>base_images</code>: Contains Dockerfiles for base images used to build the app Docker images.</li> </ul>"},{"location":"building_docker_images/#pulling-docker-images-from-harbor","title":"Pulling Docker Images From Harbor","text":"<p>To pull all images from Harbor to your local machine, execute the <code>pull_images.sh</code> script (login details are requested):</p> <pre><code>./pull_images.sh\n</code></pre> <p>If the above fails, running the command below is recommended.</p>"},{"location":"building_docker_images/#building-docker-images-locally","title":"Building Docker Images Locally","text":"<p>To build Docker images locally instead of pulling them from Harbor, execute the <code>build_images.sh</code> script: </p> <pre><code>./build_images.sh\n</code></pre>"},{"location":"building_docker_images/#running-your-own-containerized-benchmarks","title":"Running Your Own Containerized Benchmarks","text":"<p><code>iris-gpubench</code> allows you to evaluate your own containerized workloads. To use this feature:</p> <ol> <li>Build your benchmark image locally.</li> <li>Use <code>iris-gpubench</code> to run your image and collect performance metrics.</li> </ol> <p>For detailed instructions on running your own images, refer to the Command Line Interface section (Next Page).</p>"},{"location":"building_docker_images/#adding-new-benchmarks-for-developers","title":"Adding New Benchmarks (For Developers)","text":""},{"location":"building_docker_images/#steps-to-add-new-benchmarks","title":"Steps to Add New Benchmarks:","text":"<ol> <li> <p>Add Dockerfiles: Place Dockerfiles for new benchmarks in the <code>dockerfiles/app_images</code> directory. Ensure the Dockerfile extension names reflect the image names you want (e.g., <code>Dockerfile.synthetic_regression</code> will create an image named <code>synthetic_regression</code>).</p> </li> <li> <p>Custom Base Images: Store Dockerfiles for custom base images in the <code>dockerfiles/base_images</code> directory. These base images will be built first by the GitHub Actions workflows or by <code>build_images.sh</code>.</p> </li> <li> <p>Update <code>build_images.sh</code> so the can easily be built locally</p> </li> <li> <p>To add to Harbor: Update github workflow <code>docker-build.yml</code> to include them (on push/pull request to main they will be built) and as add them to <code>pull_images.sh</code>.</p> </li> <li> <p>Ensure Benchmark Specific Results are Stored Correctly: In the dockerfile save benchmark specific results to the <code>/root/results/</code> directory within the container. Additionally, record the benchmark's time score (in seconds) in a <code>metrics.yml</code> file using the key <code>time: 123</code>. This ensures that IRIS Bench can copy these results from the container before it is removed. (for more context see <code>_collect_benchmark_score</code> method in the base_monitor.py source code)</p> </li> </ol> <p>Previous Page | Index | Next Page</p>"},{"location":"collecting_results/","title":"Collecting Results","text":""},{"location":"collecting_results/#summary","title":"Summary","text":"<p>By default, results are saved to a <code>results</code> folder within the current directory where the <code>iris-gpubench</code> command is executed. If the folder does not already exist, it will be created automatically. The folder will contain the following files:</p> <ul> <li>Formatted Results Text: <code>formatted_metrics.txt</code></li> <li>GPU Metrics Timeseries Plot png: <code>metrics_plot.png</code></li> <li>Results YAML: <code>metrics.yml</code></li> </ul> <p>If the --export-to-meerkat tag is used, the timeseries data will be sent to a Grafana Dashboard. This dashboard can be used to visualize and analyze GPU metrics and performance data in a more interactive and detailed way.</p>"},{"location":"collecting_results/#formatted-results","title":"Formatted Results","text":"<ul> <li>File: <code>formatted_metrics.txt</code> </li> <li>Description: A human-readable version of the <code>metrics.yml</code> file. Provides a tabular summary of GPU and carbon performance metrics, including benchmark image name, elapsed monitor time, energy consumption, carbon emissions, and detailed GPU performance data.</li> <li>Example: <pre><code>GPU and Carbon Performance Results\n\n+-----------------------------------+-----------------------+\n| Metric                            | Value                 |\n+===================================+=======================+\n| Benchmark:                        | stemdl_classification |\n+-----------------------------------+-----------------------+\n| Benchmark Score (s)               | 578.37167             |\n+-----------------------------------+-----------------------+\n| Elapsed Monitor Time (s)          | 593.71558             |\n+-----------------------------------+-----------------------+\n| Total GPU Energy Consumed (kWh)   | 0.01593               |\n+-----------------------------------+-----------------------+\n| Total GPU Carbon Emissions (gCO2) | 1.72052               |\n+-----------------------------------+-----------------------+\n\nCarbon Information\n\n+------------------------------------+---------------------+\n| Metric                             | Value               |\n+====================================+=====================+\n| Average Carbon Forecast (gCO2/kWh) | 108.0               |\n+------------------------------------+---------------------+\n| Carbon Forecast Start Time         | 2024-09-11 14:32:20 |\n+------------------------------------+---------------------+\n| Carbon Forecast End Time           | 2024-09-11 14:42:14 |\n+------------------------------------+---------------------+\n\nGPU Information\n\n+-----------------------------------------------------+------------------------------------+\n| Metric                                              | Value                              |\n+=====================================================+====================================+\n| GPU Type                                            | NVIDIA RTX A4000                   |\n+-----------------------------------------------------+------------------------------------+\n| No. of GPUs                                         | 1                                  |\n+-----------------------------------------------------+------------------------------------+\n| Average GPU Utilization (for &gt;0.00% GPU Util.) (%)  | 63.35227                           |\n+-----------------------------------------------------+------------------------------------+\n| Average GPU Power (for &gt;0.00% GPU Util.) (W)        | 129.36336 (Power Limit: 140)       |\n+-----------------------------------------------------+------------------------------------+\n| Average GPU Temperature (for &gt;0.00% GPU Util.) (\u00b0C) | 73.80682                           |\n+-----------------------------------------------------+------------------------------------+\n| Temperature Threshold - Slowdown (\u00b0C)               | 100.00                             |\n+-----------------------------------------------------+------------------------------------+\n| Average GPU Memory (for &gt;0.00% GPU Util.) (MiB)     | 1896.26705 (Total Memory: 16376.0) |\n+-----------------------------------------------------+------------------------------------+\n| Average Clock Speed (MHz)                           | 1779.73 (Max: 2100.00)             |\n+-----------------------------------------------------+------------------------------------+\n| Average Memory Clock Speed (MHz)                    | 6500.00 (Max: 7001.00)             |\n+-----------------------------------------------------+------------------------------------+\n</code></pre></li> </ul>"},{"location":"collecting_results/#gpu-metrics-timeseries-plot-png","title":"GPU Metrics Timeseries Plot png","text":"<ul> <li>File: <code>metrics_plot.png</code> </li> <li> <p>Description: Time series plots showing GPU utilization, power usage, temperature, and memory. This plot aggregates data from multiple GPUs, including maximum power limits, peak memory usage, and total energy consumption calculated from the power usage timeseries.</p> </li> <li> <p>Example: </p> </li> </ul>"},{"location":"collecting_results/#result-metrics-yaml","title":"Result Metrics YAML","text":"<ul> <li>File: <code>metrics.yml</code> </li> <li>Description: Contains formatted data on GPU and carbon performance results. Includes metrics such as benchmark image name, elapsed monitor time, total GPU energy consumed, total carbon emissions, carbon forecast information, and detailed GPU performance data.  </li> </ul>"},{"location":"collecting_results/#gpu-metric-grafana-plots","title":"GPU Metric Grafana Plots","text":"<ul> <li> <p>Description: Exports the collected timeseries gpu metrics for a given benchmark and gpu type to Meerkat DB which is then scraped by a Grafana Dashboard.. The minimum grafana scrape interval is 10s, hence, better precision can be see in <code>metrics_plot.png</code> if the <code>--interval</code> tag is set to &lt;10s.</p> </li> <li> <p>A copy of the json queries require for this dashboard has been stored in: <code>grafana_dashboard_copyjson</code>.</p> </li> <li> <p>Example: </p> </li> </ul> <p>Previous Page | Index | Next Page</p>"},{"location":"command_line_interface/","title":"Command-Line Interface","text":"<pre><code>iris-gpubench [--benchmark-image BENCHMARK_IMAGE | --benchmark-command BENCHMARK_COMMAND] [--interval INTERVAL] [--carbon-region CARBON_REGION] [--live-plot] [--export-to-meerkat] [--monitor-logs]\n</code></pre> <p>The following optional arguments are supported:</p> <ul> <li><code>--no-live-monitor</code>: Disable live monitoring of GPU metrics. Default is enabled.</li> <li><code>--interval &lt;seconds&gt;</code>: Set the interval for collecting GPU metrics. Default is <code>5</code> seconds.</li> <li><code>--carbon-region &lt;region&gt;</code>: Specify the carbon region for the National Grid ESO Regional Carbon Intensity API. Default is <code>\"South England\"</code>.</li> <li><code>--no-plot</code>: Disable plotting of GPU metrics, saves as png. Default is enabled.</li> <li><code>--live-plot</code>: Enable live plotting of GPU metrics and saves plot to png.</li> <li><code>--export-to-meerkat</code>: Enable exporting of collected data to Meerkat DB to be scrapped by the Grafana Dashboard.</li> <li><code>--benchmark-image &lt;image&gt;</code>: Docker container image to run as a benchmark.</li> <li><code>--benchmark-command &lt;command&gt;</code>: Command to run as a benchmark in a <code>tmux</code> session. This option allows running benchmarks without Docker.</li> <li><code>--monitor-logs</code>: Enable monitoring of container or tmux logs in addition to GPU metrics.</li> </ul>"},{"location":"command_line_interface/#help-option","title":"Help Option","text":"<p>To display the help message with available options, run:</p> <pre><code>iris-gpubench --help\n</code></pre>"},{"location":"command_line_interface/#using-the-meerkat-exporter","title":"Using the Meerkat Exporter","text":"<p>For the <code>--export-to-meerkat</code> option, the Meerkat username, password, and URL must be set as environment variables. Use the following commands:</p> <pre><code>export MEERKAT_USERNAME='insert_username'\nexport MEERKAT_PASSWORD='insert_password'\nexport MEERKAT_URL='https://172.16.101.182:8247/write' \n</code></pre> <p>(As of 12/09/24, this is the correct URL.)</p>"},{"location":"command_line_interface/#useful-to-know","title":"Useful to know","text":"<ul> <li>Either <code>--benchmark-image</code> or <code>--benchmark-command</code> must be provided, but not both. If both options are specified, an error will be raised.</li> <li>Live GPU metrics monitoring and saving a final plot are enabled by default; use <code>--no-live-monitor</code> and <code>--no-plot</code> to disable them, respectively.</li> <li>To view the available carbon regions, use <code>--carbon-region \"\"</code> to get a list of all regions.</li> <li>To list available Docker images, use <code>--benchmark-image \"\"</code> for a list of images.</li> </ul> <p>For example commands please see the next page.</p> <p>Previous Page | Index | Next Page</p>"},{"location":"considerations_on_accuracy/","title":"Considerations On Accuracy","text":""},{"location":"considerations_on_accuracy/#carbon-metrics-accuracy-limitations","title":"Carbon Metrics Accuracy Limitations","text":"<ul> <li>The Carbon Data is collected in real-time from the National Grid ESO Regional Carbon Intensity API.</li> <li>The Carbon Forecast Readings are updated every 30 minutes. The monitor records the index values at the start and end of each interval and calculates an average. Therefore, the accuracy may be limited for containers that run longer than 30 minutes, as the index can fluctuate significantly over time.</li> <li>The Carbon Forecast can vary based on factors such as weather, time of day/year, and energy demand, resulting in fluctuations in total carbon emissions from one run to the next. Therefore, it serves as a real-time estimate. For a broader perspective, you can multiply the total energy by the average Carbon Emission Rate in the UK, which was 162 gCO2/kWh in 2023.</li> <li>For more on Enhancing Carbon Footprint Accuracy please go to Future Work section.</li> </ul>"},{"location":"considerations_on_accuracy/#gpu-metrics-accuracy-limitions","title":"GPU Metrics Accuracy Limitions","text":"<ul> <li>The GPU metrics come from pynvml which is a python interface for NVML and \"nvidia-smi\" results.</li> <li>The \"error in nvidia-smi's power draw is \u00b1 5%\".</li> <li>Total energy is calculated by integrating power readings over time using the trapezoidal integration method. The accuracy of this calculation depends on the monitoring interval: a smaller interval results in more accurate energy estimates.</li> </ul>"},{"location":"considerations_on_accuracy/#profiling-the-monitors-impact-on-gpu-resources","title":"Profiling the Monitors Impact on GPU Resources","text":"<ul> <li>(Minimal) GPU Resource Usage by the Monitor: The monitoring tool consumes a small portion of GPU resources. For instance, a ~5-minute test done on a VM with a V100 GPU and the dummy benchmark container shows negligible GPU usage, see below. CPU resources are also utilized, though profiling tests to determine exact CPU usage have not yet been conducted.</li> </ul> <pre><code>GPU and Carbon Performance Results\n\n+---------------------------------------+---------+\n| Metric                                | Value   |\n+=======================================+=========+\n| Benchmark Image Name                  | dummy   |\n+---------------------------------------+---------+\n| Elapsed Monitor Time of Container (s) | 320.177 |\n+---------------------------------------+---------+\n| Total GPU Energy Consumed (kWh)       | 0.00183 |\n+---------------------------------------+---------+\n| Total GPU Carbon Emissions (gCO2)     | 0.36118 |\n+---------------------------------------+---------+\n</code></pre> <ul> <li>These are idle usage levels, so monitoring the GPUs has a negligible impact on GPU resources.</li> </ul> <p>Previous Page | Index | Next Page</p>"},{"location":"example_commands/","title":"Example Commands","text":""},{"location":"example_commands/#example-usage","title":"Example Usage","text":""},{"location":"example_commands/#example-1-basic-monitoring-with-completion-plot","title":"Example 1: Basic Monitoring with Completion Plot:","text":"<pre><code>iris-gpubench --benchmark-image \"synthetic_regression\"\n</code></pre> <ul> <li>Explanation: This command runs GPU monitoring while executing the benchmark specified by the Docker image <code>synthetic_regression</code>. The system will collect GPU metrics and generate a completion plot at the end. Live monitoring of GPU metrics is enabled by default.</li> </ul>"},{"location":"example_commands/#example-2-exporting-data-to-victoriametrics","title":"Example 2: Exporting Data to VictoriaMetrics:","text":"<pre><code>iris-gpubench --benchmark-image \"synthetic_regression\" --export-to-meerkat\n</code></pre> <ul> <li>Explanation: Similar to the first example, this command runs the <code>synthetic_regression</code> Docker image benchmark and collects GPU metrics. Additionally, the collected data is exported to Meerkat for long-term storage and further analysis. This is useful when you need to monitor metrics over time and visualize them later using external tools such as the Grafana Dashboard.</li> </ul>"},{"location":"example_commands/#example-3-full-command-with-all-options","title":"Example 3: Full Command with All Options:","text":"<pre><code>iris-gpubench --benchmark-image \"stemdl_classification\" --interval 10 --carbon-region \"South England\" --live-plot --export-to-meerkat --monitor-logs\n</code></pre> <ul> <li>Explanation: This is a comprehensive example that runs the <code>stemdl_classificatio</code> benchmark in a Docker container and collects GPU metrics at a 10-second interval. The <code>--carbon-region</code> flag specifies the carbon intensity region as \"South England\" to track the carbon emissions impact. Live plotting of GPU metrics is enabled (<code>--live-plot</code>), and data will be exported to Meerkat DB via VictoriaMetrics (<code>--export-to-meerkat</code>). The <code>--monitor-logs</code> flag enables logging of both GPU metrics and the Docker container logs, allowing for deeper analysis of benchmark performance.</li> </ul>"},{"location":"example_commands/#example-4-run-and-monitor-benchmark-in-the-background-without-the-need-for-a-container","title":"Example 4: Run and Monitor Benchmark in the Background without the Need for a Container:","text":"<pre><code>/mantid_imaging_cloud_bench$ iris-gpubench --benchmark-command \"./run_1.sh\" --live-plot --interval 1\n</code></pre> <ul> <li>Explanation: In this example, a benchmark command (<code>./run_1.sh</code>) is executed in the background using <code>tmux</code> instead of a Docker container. GPU metrics are collected at 1-second intervals, and live plotting of these metrics is enabled. This is useful when you have a script or binary that doesn't require containerization and want to monitor the system's GPU usage in real-time. Running benchmarks in <code>tmux</code> allows the process to continue in the background, making it ideal for long-running benchmarks that don't need constant attention.</li> <li>Important: For this example, you'll need to install you benchmark on the VM and the iris-gpubench package.</li> </ul> <p>Previous Page | Index | Next Page</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#pre-installation-instructions","title":"Pre-Installation Instructions","text":""},{"location":"installation/#1-set-up-ubuntu-vm","title":"1. Set Up Ubuntu VM:","text":"<ul> <li>Start with an Ubuntu VM equipped with Nvidia GPUs.</li> </ul>"},{"location":"installation/#2-install-dependencies","title":"2. Install Dependencies:","text":"<ul> <li> <p>For Docker Benchmarks: Install Docker, Nvidia Docker (for GPU support), git, Python with Virtual Environment, and Nvidia drivers.</p> </li> <li> <p>For Direct Machine Benchmarks: Install Tmux, git, Python with Virtual Environment, and Nvidia drivers.</p> </li> </ul>"},{"location":"installation/#3-setup-vm-with-script-requires-git-to-clone-repo","title":"3. Setup VM With Script (requires git to clone repo):","text":"<ul> <li> <p>Docker Benchmarks: Execute <code>./setup_vm_docker.sh</code> from the cloned Git repository.</p> </li> <li> <p>Direct Machine Benchmarks: Execute <code>./setup_vm_tmux.sh</code> from the cloned Git repository.</p> </li> </ul>"},{"location":"installation/#installation-instructions","title":"Installation Instructions","text":"<p>Follow these steps to set up iris-gpubench:</p>"},{"location":"installation/#1clone-the-repository","title":"1.Clone the Repository","text":"<p>Start by cloning the project repository: <pre><code>git clone https://github.com/bryceshirley/iris-gpubench.git\ncd iris-gpubench\n</code></pre></p>"},{"location":"installation/#2set-up-a-virtual-environment","title":"2.Set Up a Virtual Environment","text":"<p>Next, create and activate a virtual environment: <pre><code>python3 -m venv env\nsource env/bin/activate\n</code></pre></p>"},{"location":"installation/#3install-dependencies-and-iris-gpubench-package","title":"3.Install Dependencies and iris-gpubench Package","text":""},{"location":"installation/#a-finally-install-the-package-along-with-necessary-dependencies","title":"a. Finally, install the package along with necessary dependencies:","text":"<pre><code>pip install wheel\npip install .\n</code></pre>"},{"location":"installation/#b-for-developers","title":"b. (For Developers)","text":"<p><pre><code>pip install wheel\npip install -e .\n</code></pre>    -  <code>-e</code> for editable mode, lets you install Python packages in a way that    allows immediate reflection of any changes you make to the source code    without needing to reinstall the package.</p> <p>Previous Page | Index | Next Page</p>"},{"location":"live_monitoring/","title":"Live Monitoring","text":""},{"location":"live_monitoring/#monitor-gpu-metrics","title":"Monitor GPU Metrics","text":"<p>A default option that can be switched off.</p> <pre><code>Current GPU Metrics (Tesla V100-PCIE-32GB) as of 2024-09-12 16:53:14:\n+--------------------------+----------+---------+\n| Metric                   |    GPU 0 |   GPU 1 |\n+==========================+==========+=========+\n| Utilization (%)          |   97     |   0     |\n+--------------------------+----------+---------+\n| Power (W)                |  178.133 |  27.284 |\n+--------------------------+----------+---------+\n| Temperature (C)          |   49     |  35     |\n+--------------------------+----------+---------+\n| Memory (MiB)             | 6793.62  | 275.625 |\n+--------------------------+----------+---------+\n| Clock Speed (MHz)        | 1380     | 135     |\n+--------------------------+----------+---------+\n| Memory Clock Speed (MHz) |  877     | 877     |\n+--------------------------+----------+---------+\n</code></pre>"},{"location":"live_monitoring/#monitor-benchmark-containertmux-logs","title":"Monitor Benchmark Container/Tmux Logs","text":"<pre><code>gpu_monitor --benchmark-image \"synthetic_regression\" --monitor-logs\n\nContainer Logs:\n&lt;BEGIN&gt; Running benchmark synthetic_regression in training mode\n....&lt;BEGIN&gt; Parsing input arguments\n....&lt;ENDED&gt; Parsing input arguments [ELAPSED = 0.000035 sec]\n....&lt;BEGIN&gt; Creating dataset\n....&lt;ENDED&gt; Creating dataset [ELAPSED = 12.436691 sec]\n....&lt;MESSG&gt; Number of samples: 1024000\n....&lt;MESSG&gt; Total number of batches: 8000, 8000.0\n....&lt;BEGIN&gt; Training model\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/root/anaconda3/envs/bench/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name | Type       | Params | Mode \n--------------------------------------------\n0 | net  | Sequential | 250 M  | train\n--------------------------------------------\n250 M     Trainable params\n0         Non-trainable params\n250 M     Total params\n1,000.404 Total estimated model params size (MB)\n11        Modules in train mode\n0         Modules in eval mode\n/root/anaconda3/envs/bench/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\nEpoch 0:   4%|\u258d         | 350/8000 [00:09&lt;03:23, 37.56it/s, v_num=0]\n</code></pre> <p>(Long container logs containing \"\\r\" to clear the line for progress bars are not a very efficiently processed, as it captures a snapshot of the entire container log at that moment. Potiential solution: use asynico package to capture and process the logs whilst the monitor is paused between intervals)</p>"},{"location":"live_monitoring/#save-png-timeseries-plot-live","title":"(Save png) Timeseries Plot Live","text":"<p>Gives you saves plot png during every reading so that the metrics can be viewed live locally.</p> <p>Example command and Results: <pre><code>gpu_monitor --benchmark-image \"stemdl_classification_2gpu\" --plot_live\n</code></pre> This command was run on a VM with 2 V100 GPUs for the results in Collecting Results Section.</p>"},{"location":"live_monitoring/#grafana-timeseries-plot-live","title":"(Grafana) Timeseries Plot Live","text":"<p>If the <code>--export-to-meerkat</code> tag is used the results can be viewed live from the Grafana Dashboard. Data from multiple VMs can be collected all at once allowing for a live comparison of performance as well.</p> <p>See example results Collecting Results Section.</p> <p>Previous Page | Index | Next Page</p>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#overview","title":"Overview","text":"<p>The GPU Monitoring and Carbon Calculation Tool <code>iris-gpubench</code> monitors GPU performance and estimates carbon emissions during benchmarks.</p>"},{"location":"overview/#key-features","title":"Key Features","text":"<ul> <li> <p>GPU Monitoring: Tracks real-time metrics such as utilization, power, temperature, and memory usage.</p> </li> <li> <p>Carbon Emissions Calculation: Estimates emissions using the National Grid ESO Regional Carbon Intensity API based on GPU energy consumption.</p> </li> <li> <p>Export to VictoriaMetrics: Optionally exports data to Grafana for long-term storage and analysis.</p> </li> <li> <p>Flexible Benchmarking:  </p> </li> <li>Docker: Run benchmarks in a consistent, isolated environment.</li> <li> <p>Tmux: Execute benchmarks directly on the host system for quick setups.</p> </li> <li> <p>Command-Line Interface: Customizable options for intervals, carbon calculations, live plotting, and more.</p> </li> <li> <p>Live Monitoring and Logging: Supports real-time GPU monitoring and logging from Docker containers and Tmux sessions.</p> </li> </ul>"},{"location":"overview/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Informed Purchasing: Evaluate and compare performance across different hardware configurations before making purchasing decisions.</p> </li> <li> <p>Benchmarking: Assess GPU-accelerated applications' performance.</p> </li> <li> <p>Environmental Impact: Quantify carbon emissions from GPU usage.</p> </li> <li> <p>Performance Optimization: Identify and resolve performance bottlenecks.</p> </li> </ul> <p>Previous Page | Index | Next Page</p>"},{"location":"work_to_do/","title":"Future Work and Expansion","text":""},{"location":"work_to_do/#1-additional-benchmarks-to-integrate","title":"1 Additional Benchmarks to Integrate","text":"<ul> <li> <p>McStas Neutron Monte Carlo Ray-Tracing</p> </li> <li> <p>RFI GPU Benchmarks: Explore and integrate relevant Radio Frequency Interference (RFI) GPU benchmarks to cover a wider range of scientific performance evaluations.</p> </li> <li> <p>Highly Optimized NVIDIA HPL Benchmarks: Add the NVIDIA HPC Benchmarks, focusing on the HPL benchmarks designed for Grace Hopper tests. This integration will require referencing the NVIDIA HPL Benchmark documentation to ensure proper implementation and optimization.</p> </li> </ul>"},{"location":"work_to_do/#2-enhancing-benchmark-results","title":"2 Enhancing Benchmark Results","text":"<ul> <li> <p>Integration into Meerkat (HIGH PRIORITY): Complete the integration with Meerkat to facilitate regular benchmark testing. This will allow the generation of more robust statistical data, such as error bars, by calculating mean and standard deviation across multiple tests.</p> </li> <li> <p>Normalization of Results: Implement normalization techniques to standardize benchmark results across different GPU models and workloads, facilitating meaningful comparisons.</p> </li> <li> <p>FLOP Estimations and Efficiency Metrics: Calculate Floating Point Operations per Second (FLOPs) to determine performance per watt, providing insights into computational efficiency and energy consumption.</p> </li> </ul>"},{"location":"work_to_do/#21-estimating-floating-point-operations-per-second-flops","title":"2.1 Estimating Floating Point Operations Per Second (FLOPs)","text":"<p>Comparisons based solely on clock speed can be misleading due to differences in GPU architectures, CUDA cores, tensor cores, and operations per clock cycle. Note clock speeds vary for various reasons such as size of workload, temperature, and power supply.</p> <p>To estimate the FLOPs of a GPU:</p> <p>FLOPs = CUDA Cores \u00d7 Clock Speed (Hz) \u00d7 Operations per Clock Cycle</p> <p>Steps to calculate FLOPs:</p> <ol> <li>Determine the number and type of cores (e.g., CUDA cores, tensor cores) and if they are being utilized.</li> <li>Clock speed can be found using IRIS BENCH.</li> <li>Identify the operations per clock cycle, specific to the GPU's architecture (i.e., core generation). \"The A100 SM includes new third-generation Tensor Cores that each perform 256 FP16/FP32 FMA operations per clock.\"</li> <li>Investigate how <code>nvidia-smi</code> calculates utilization and whether more granular utilization data can be obtained.</li> <li>Review how tools like sciml-bench and pytorch report core usage and incorporate these insights into metrics collection.</li> </ol> <p>Data Sheets Contain Information About the Number of Cores</p> <ul> <li>V100 datasheet</li> <li>A4000 Datasheet</li> <li>NVIDIA A100 Datasheet</li> <li>RTX4000 DataSheet</li> </ul>"},{"location":"work_to_do/#3-explore-nvidia-nsight-systems","title":"3 Explore NVIDIA Nsight Systems","text":"<p>Utilize NVIDIA Nsight Systems for detailed performance profiling, identifying optimization opportunities, and potentially getting insight into the activated cores for FLOP calculations. This tool offers in-depth insights into GPU performance across various workloads and configurations.</p>"},{"location":"work_to_do/#4-enhancing-carbon-footprint-accuracy","title":"4 Enhancing Carbon Footprint Accuracy","text":"<p>To achieve a more accurate total carbon footprint, emissions from the GPU's manufacturing, delivery, and full lifecycle should be included. This requires calculating the proportion of the GPU's lifespan used by a specific workload and converting it to equivalent carbon emissions, which are then added to emissions from the API and electricity use.</p> <p>Cooling power should also be considered; while <code>nvidia-smi</code> does not report fan power directly, fan speed data can be used to estimate it.</p> <p>The revised calculation includes:</p> <ul> <li> <p>Manufacturing Emissions per Hour: <pre><code>Manufacturing Emissions per Hour = Total Manufacturing Emissions (kg CO\u2082e) / Expected Lifespan (hours)\n</code></pre></p> </li> <li> <p>Delivery Emissions per Hour: <pre><code>Delivery Emissions per Hour = Total Delivery Emissions (kg CO\u2082e) / Expected Lifespan (hours)\n</code></pre></p> </li> <li> <p>Use Emissions for the Run (already calculated by IRIS Bench): <pre><code>Use Emissions for the Run = (Power Consumption (Watts) / 1000) * Run Time (hours) * Carbon Intensity from API (kg CO\u2082e per kWh)\n</code></pre></p> </li> <li> <p>Cooling Emissions for the Run (based on fan speed): <pre><code>Cooling Emissions for the Run = (Estimated Fan Power (Watts) / 1000) * Run Time (hours) * Carbon Intensity from API (kg CO\u2082e per kWh)\n</code></pre></p> </li> <li> <p>Total Emissions for the Run: <pre><code>Total Emissions for the Run = (Manufacturing Emissions per Hour + Delivery Emissions per Hour) * Run Time (hours) + Use Emissions for the Run + Cooling Emissions for the Run\n</code></pre></p> </li> </ul> <p>This approach will provide a more comprehensive estimate of the carbon footprint for GPU workloads.</p>"},{"location":"work_to_do/#41-estimating-embodied-carbon-if-manufacturers-dont-provide-them","title":"4.1 Estimating Embodied Carbon if Manufacturers Don\u2019t Provide Them","text":"<p>Finding specific statistics on the embodied carbon emissions associated with the manufacturing and packaging of NVIDIA GPUs proved challenging. However, the paper Toward Sustainable HPC: Carbon Footprint Estimation and Environmental Implications of HPC Systems provides a model for estimating embodied carbon using available data on GPUs (as well as CPU, Memory, and Storage). For detailed insights, please refer to Section 2.1, titled \"Embodied Carbon Footprint Modeling.\"</p>"},{"location":"work_to_do/#5-strategic-planning-for-energy-intensive-tasks-based-on-carbon-intensity-forecasts","title":"5 Strategic Planning for Energy-Intensive Tasks Based on Carbon Intensity Forecasts","text":""},{"location":"work_to_do/#51-overview","title":"5.1 Overview","text":"<p>This section focuses on guiding policies for executing energy-intensive tasks at STFC. By utilizing carbon intensity forecasts from the National Grid ESO Carbon Intensity API Carbon Intensity API, users can determine the optimal timing for these operations.</p> <p>Scheduling tasks during periods of low carbon intensity or in regions with lower emissions\u2014such as comparing Daresbury and RAL\u2014can effectively reduce users' carbon footprints. Factors such as seasonal variations (summer vs. winter) and time of day significantly impact carbon intensity. Making informed decisions based on these variables can lead to substantial reductions in carbon emissions.</p>"},{"location":"work_to_do/#53-regional-carbon-intensity-variation","title":"5.3 Regional Carbon Intensity Variation","text":"<p>The table below, sourced from Carbon Intensity API, illustrates the variation in carbon intensity across different regions. At the time this screenshot was captured, the carbon intensity for the Daresbury Lab region was 21 gCO2/kWh, while RAL's region recorded 76 gCO2/kWh. Running a program at the Hartree Centre instead of RAL during this period could potentially reduce carbon emissions by approximately 70%, assuming the same hardware and setup are available.</p> <p></p>"},{"location":"work_to_do/#54-emissions-forecasting","title":"5.4 Emissions Forecasting","text":"<p>As shown in the plot below from Carbon Intensity API, actual emissions closely align with forecasted values. Running an energy-intensive task between September 27 at 00:00 and 12:00, rather than from September 28 at 00:00 to 12:00, could result in an approximately 50% reduction in carbon usage.</p> <p></p>"},{"location":"work_to_do/#55-integration-with-iris-bench","title":"5.5 Integration with IRIS Bench","text":"<p>Connecting this back to benchmarks\u2014IRIS Bench provides users with insights into the duration and energy consumption of workloads similar to theirs on available GPUs. When combined with carbon intensity forecasts gathered regionally before the intended execution time, users can estimate carbon emissions for a workload before it is run. This predictive capability would be a valuable addition to IRIS Bench, allowing users to make informed decisions about the environmental impact of their tasks prior to execution.</p> <p>The example below, taken from the Carbon Intensity API on 27-09-2024, provides a carbon forecast through 29-09-2024 and demonstrates the ability to select specific regions for tailored predictions.</p> <p></p>"},{"location":"work_to_do/#formula-for-predicting-carbon-emissions","title":"Formula for Predicting Carbon Emissions","text":"<p>Carbon_Prediction: Estimated total carbon emissions (gCO2) of the task.</p> <ul> <li> <p>Benchmark_Average_Power(GPU_Type): Average power consumption of the workload from IRIS Bench Results Database for a specific GPU type (W).</p> </li> <li> <p>Intended_Run_Start: Planned start time for the task (timestamp).</p> </li> <li> <p>Benchmark_RunTime(GPU_Type): Estimated duration of the task from IRIS Bench Results Database for a specific GPU type (hours).</p> </li> <li> <p>Carbon_Intensity_Forecast(t, Region): Forecasted carbon intensity at time t in a specific region (gCO2/kWh).</p> </li> <li> <p>t: Variable of integration representing time.</p> </li> <li> <p>Region: Geographical area of execution affecting carbon intensity.</p> </li> <li> <p>GPU_Type: The specific model of GPU utilized for the task. The calculation can be repeated for each available GPU to provide a comprehensive summary.</p> </li> </ul>"},{"location":"work_to_do/#56-an-example-from-wwf","title":"5.6 An Example from WWF","text":"<p>WWF has integrated the API into a reusable widget designed to help reduce emissions by turning on devices during periods of green energy and off when it's not. STFC Cloud could create a similar solution for its users to enhance carbon emission management.</p> <p> Screen print from WWF</p>"},{"location":"work_to_do/#6-additional-metrics-and-areas-for-measurement-in-iris-bench","title":"6 Additional Metrics and Areas for Measurement in IRIS Bench","text":"<ul> <li> <p>Utilization Time: Measure the total time the GPU is actively utilized, which can provide insights into idle periods and workload efficiency.</p> </li> <li> <p>Stability: Crash Frequency: Track and report any GPU crashes or visual artifacts during benchmarks to assess stability.</p> </li> <li> <p>Throttling Events: Monitor instances of clock speed reductions due to high temperatures or power constraints.</p> </li> <li> <p>Memory Bandwidth: Measure the data transfer rate between the GPU and system memory to identify potential bottlenecks and optimize performance.</p> </li> </ul>"},{"location":"work_to_do/#7-other-ideas-for-future-implementation","title":"7 Other Ideas for Future Implementation","text":"<ul> <li> <p>Consistent Hardware Configurations: Ensure that all GPUs being tested use the same hardware configurations (e.g., memory, CPUs) to eliminate variability and produce consistent results.</p> </li> <li> <p>Continuous Integration for Performance Testing: Encourage IRIS users to integrate GPU benchmarks into their CI workflows. Implement automated performance tests on every pull request; if performance drops by a specified percentage, the pull request would fail, ensuring that code changes do not degrade performance.</p> </li> <li> <p>Experimenting with Precision to Utilize Tensor Cores Fully: For GPUs equipped with tensor cores, utilize lower precisions (e.g., FP16) for matrix</p> </li> </ul> <p>operations where feasible. This can lead to significant performance gains, depending on the workload's precision requirements.</p>"},{"location":"work_to_do/#8-improvements-for-github-repository","title":"8 Improvements for GitHub Repository","text":"<ul> <li>Continuous Integration (CI) Tests: Develop and integrate comprehensive CI tests using GitHub Actions to maintain code reliability, ensure consistent performance, and catch issues early in the development cycle.</li> <li>Carbon Index Calculation: Enhance the environmental impact analysis by calculating the carbon index throughout the entire benchmarking run, rather than just at the start and end, to provide a more accurate representation.</li> <li>Wider Carbon Cost View: * It would be good to also investigate carbon associated with the manufacturing, delivery and lifetime of the GPU to. Ie how much of the lifetime was consumed by the run and how does that equate to carbon emissions.</li> <li>Use Best Practices for Naming Dockerfiles: Ensure all Dockerfiles follow standard naming conventions for clarity and maintainability.</li> <li>Include Logging Levels: Implement various logging levels (e.g., debug, info, error) and log tagging to improve traceability and debugging.</li> <li>Add Shell Check Workflow: Integrate a shell check workflow, similar to the one used in the SCD-OpenStack-Utils repository, to catch errors in shell scripts.</li> <li>Run Shell Check from Bash Scripts: Use shell check (similar to pylint) to analyze bash scripts for potential issues and maintain code quality.</li> <li>Add Dependabot to GitHub Actions: Implement Dependabot for automated dependency updates, improving security and ensuring compatibility with new releases.</li> </ul> <p>Previous Page | Index</p>"}]}